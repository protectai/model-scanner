{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Installing ModelScan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n",
      "modelscan, version 0.0.0\n"
     ]
    }
   ],
   "source": [
    "%pip install -q modelscan\n",
    "!modelscan -v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -q torch==2.0.1\n",
    "%pip install -q transformers==4.31.0\n",
    "%pip install -q scipy==1.11.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: TOKENIZERS_PARALLELISM=false\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vscode/.cache/pypoetry/virtualenvs/modelscan-d-AHl6rn-py3.9/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import os\n",
    "from utils.pytorch_sentiment_model import download_model, predict_sentiment\n",
    "from utils.pickle_codeinjection import PickleInject, get_payload\n",
    "\n",
    "%env TOKENIZERS_PARALLELISM=false"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Saving Model\n",
    "\n",
    "\n",
    "The BERT based sentiment analysis PyTorch model used in the notebook can be found at https://huggingface.co/cardiffnlp/twitter-roberta-base-sentiment. The safe model is saved at `./PyTorchModels/safe_model.pt`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "nbmake": {
     "post_cell_execute": [
      "import os\n",
      "assert os.path.isfile(safe_model_path)"
     ]
    }
   },
   "outputs": [],
   "source": [
    "# Save a model for sentiment analysis\n",
    "from typing import Final\n",
    "\n",
    "model_directory: Final[str] = \"PyTorchModels\"\n",
    "if not os.path.isdir(model_directory):\n",
    "    os.mkdir(model_directory)\n",
    "\n",
    "safe_model_path = os.path.join(model_directory, \"safe_model.pt\")\n",
    "\n",
    "download_model(safe_model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Safe Model Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "nbmake": {
     "post_cell_execute": [
      "assert sentiment == 'The overall sentiment is: negative with a score of: 85.9%'"
     ]
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The overall sentiment is: negative with a score of: 85.9%'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentiment = predict_sentiment(\n",
    "    \"Stock market was bearish today\", torch.load(safe_model_path)\n",
    ")\n",
    "sentiment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scan Safe Model\n",
    "\n",
    "The scan results include information on the files scanned, and any issues if found. For the safe model scanned, modelscan finds no model serialization attacks, as expected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "nbmake": {
     "post_cell_execute": [
      "import json\n",
      "!modelscan --path PyTorchModels/safe_model.pt --reporting-format=json --output-file PyTorchModels/safe_model_results.json\n",
      "with open('PyTorchModels/safe_model_results.json', 'rb') as f:\n",
      "    data = json.load(f)\n",
      "summary = data['summary']\n",
      "assert summary['input_path'] == 'PyTorchModels/safe_model.pt'\n",
      "assert summary['total_issues_by_severity'] == {'LOW': 0, 'MEDIUM': 0, 'HIGH': 0, 'CRITICAL': 0}\n",
      "assert summary['total_issues'] == 0\n",
      "assert summary['scanned']['total_scanned'] == 1\n",
      "assert data['issues'] == []\n",
      "assert data['errors'] == []"
     ]
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No settings file detected at /workspaces/modelscan/notebooks/modelscan-settings.toml. Using defaults. \n",
      "\n",
      "Scanning /workspaces/modelscan/notebooks/PyTorchModels/safe_model.pt:safe_model/data.pkl using modelscan.scanners.PickleUnsafeOpScan model scan\n",
      "\n",
      "\u001b[34m--- Summary ---\u001b[0m\n",
      "\n",
      "\u001b[32m No issues found! ðŸŽ‰\u001b[0m\n",
      "\n",
      "\u001b[34m--- Skipped --- \u001b[0m\n",
      "\n",
      "Total skipped: \u001b[1;36m204\u001b[0m - run with --show-skipped to see the full list.\n"
     ]
    }
   ],
   "source": [
    "!modelscan --path PyTorchModels/safe_model.pt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Serialization Attack\n",
    "\n",
    "Here malicious code is injected in the safe model to read aws secret keys. The unsafe model is saved at `./PyTorchModels/unsafe_model.pt`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "nbmake": {
     "post_cell_execute": [
      "assert os.path.isfile(unsafe_model_path)"
     ]
    }
   },
   "outputs": [],
   "source": [
    "command = \"system\"\n",
    "malicious_code = \"\"\"cat ~/.aws/secrets\n",
    "    \"\"\"\n",
    "\n",
    "unsafe_model_path = os.path.join(model_directory, \"unsafe_model.pt\")\n",
    "\n",
    "payload = get_payload(command, malicious_code)\n",
    "torch.save(\n",
    "    torch.load(safe_model_path),\n",
    "    f=unsafe_model_path,\n",
    "    pickle_module=PickleInject([payload]),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Unsafe Model Prediction\n",
    "\n",
    "The malicious code injected in the unsafe model gets executed when it is loaded. The aws secret keys are displayed. \n",
    "\n",
    "Also, the unsafe model predicts the sentiments just as well as safe model i.e., the code injection attack will not impact the model performance. The unaffected performance of unsafe models makes the ML models an effective attack vector. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "nbmake": {
     "post_cell_execute": [
      "assert sentiment == 'The overall sentiment is: negative with a score of: 85.9%'"
     ]
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aws_access_key_id=AKIAIOSFODNN7EXAMPLE\n",
      "aws_secret_access_key=wJalrXUtnFEMI/K7MDENG/bPxRfiCYEXAMPLEKEY\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'The overall sentiment is: negative with a score of: 85.9%'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentiment = predict_sentiment(\n",
    "    \"Stock market was bearish today\", torch.load(unsafe_model_path)\n",
    ")\n",
    "sentiment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scan Unsafe Model\n",
    "\n",
    "The scan results include information on the files scanned, and any issues if found. In this case, a critical severity level issue is found in the unsafe model scanned. \n",
    "\n",
    "modelscan also outlines the found operator(s) and module(s) deemed unsafe. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No settings file detected at /workspaces/modelscan/notebooks/modelscan-settings.toml. Using defaults. \n",
      "\n",
      "Scanning /workspaces/modelscan/notebooks/PyTorchModels/unsafe_model.pt:unsafe_model/data.pkl using modelscan.scanners.PickleUnsafeOpScan model scan\n",
      "\n",
      "\u001b[34m--- Summary ---\u001b[0m\n",
      "\n",
      "Total Issues: \u001b[1;36m1\u001b[0m\n",
      "\n",
      "Total Issues By Severity:\n",
      "\n",
      "    - LOW: \u001b[1;32m0\u001b[0m\n",
      "    - MEDIUM: \u001b[1;32m0\u001b[0m\n",
      "    - HIGH: \u001b[1;32m0\u001b[0m\n",
      "    - CRITICAL: \u001b[1;36m1\u001b[0m\n",
      "\n",
      "\u001b[34m--- Issues by Severity ---\u001b[0m\n",
      "\n",
      "\u001b[34m--- CRITICAL ---\u001b[0m\n",
      "\n",
      "Unsafe operator found:\n",
      "  - Severity: CRITICAL\n",
      "  - Description: Use of unsafe operator 'system' from module 'posix'\n",
      "  - Source: /workspaces/modelscan/notebooks/PyTorchModels/unsafe_model.pt:unsafe_model/data.pkl\n",
      "\n",
      "\u001b[34m--- Skipped --- \u001b[0m\n",
      "\n",
      "Total skipped: \u001b[1;36m204\u001b[0m - run with --show-skipped to see the full list.\n"
     ]
    }
   ],
   "source": [
    "!modelscan --path  ./PyTorchModels/unsafe_model.pt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reporting Format\n",
    "ModelScan can report scan results in console (default), json, or custom report (to be defined by user in settings-file). For mode details, please see:  ` modelscan -h` "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## JSON Report\n",
    "\n",
    "For JSON reporting: `modelscan -p ./path-to/file -r json -o output-file-name.json` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "nbmake": {
     "post_cell_execute": [
      "import json\n",
      "with open('PyTorchModels/pytorch-model-scan-results.json', 'rb') as f:\n",
      "    data = json.load(f)\n",
      "summary = data['summary']\n",
      "assert summary['input_path'] == './PyTorchModels/unsafe_model.pt'\n",
      "assert summary['total_issues_by_severity'] == {'LOW': 0, 'MEDIUM': 0, 'HIGH': 0, 'CRITICAL': 1}\n",
      "assert summary['total_issues'] == 1\n",
      "assert summary['scanned']['total_scanned'] == 1\n",
      "assert data['issues'] == [{'description': 'Use of unsafe operator \\'system\\' from module \\'posix\\'', 'operator': 'system', 'module': 'posix', 'source': 'unsafe_model.pt:unsafe_model/data.pkl', 'scanner': 'modelscan.scanners.PickleUnsafeOpScan', 'severity': 'CRITICAL'}]\n",
      "assert len(data['errors']) == 0"
     ]
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No settings file detected at /workspaces/modelscan/notebooks/modelscan-settings.toml. Using defaults. \n",
      "\n",
      "Scanning /workspaces/modelscan/notebooks/PyTorchModels/unsafe_model.pt:unsafe_model/data.pkl using modelscan.scanners.PickleUnsafeOpScan model scan\n",
      "\u001b[1m{\u001b[0m\u001b[32m\"summary\"\u001b[0m: \u001b[1m{\u001b[0m\u001b[32m\"total_issues_by_severity\"\u001b[0m: \u001b[1m{\u001b[0m\u001b[32m\"LOW\"\u001b[0m: \u001b[1;36m0\u001b[0m, \u001b[32m\"MEDIUM\"\u001b[0m: \u001b[1;36m0\u001b[0m, \u001b[32m\"HIGH\"\u001b[0m: \u001b[1;36m0\u001b[0m, \n",
      "\u001b[32m\"CRITICAL\"\u001b[0m: \u001b[1;36m1\u001b[0m\u001b[1m}\u001b[0m, \u001b[32m\"total_issues\"\u001b[0m: \u001b[1;36m1\u001b[0m, \u001b[32m\"input_path\"\u001b[0m: \n",
      "\u001b[32m\"./PyTorchModels/unsafe_model.pt\"\u001b[0m, \u001b[32m\"absolute_path\"\u001b[0m: \n",
      "\u001b[32m\"/workspaces/modelscan/notebooks/PyTorchModels\"\u001b[0m, \u001b[32m\"modelscan_version\"\u001b[0m: \u001b[32m\"0.0.0\"\u001b[0m, \n",
      "\u001b[32m\"timestamp\"\u001b[0m: \u001b[32m\"2024-04-21T10:49:44.690078\"\u001b[0m, \u001b[32m\"scanned\"\u001b[0m: \u001b[1m{\u001b[0m\u001b[32m\"total_scanned\"\u001b[0m: \u001b[1;36m1\u001b[0m, \n",
      "\u001b[32m\"scanned_files\"\u001b[0m: \u001b[1m[\u001b[0m\u001b[32m\"unsafe_model.pt:unsafe_model/data.pkl\"\u001b[0m\u001b[1m]\u001b[0m\u001b[1m}\u001b[0m\u001b[1m}\u001b[0m, \u001b[32m\"issues\"\u001b[0m: \n",
      "\u001b[1m[\u001b[0m\u001b[1m{\u001b[0m\u001b[32m\"description\"\u001b[0m: \u001b[32m\"Use of unsafe operator 'system' from module 'posix'\"\u001b[0m, \n",
      "\u001b[32m\"operator\"\u001b[0m: \u001b[32m\"system\"\u001b[0m, \u001b[32m\"module\"\u001b[0m: \u001b[32m\"posix\"\u001b[0m, \u001b[32m\"source\"\u001b[0m: \n",
      "\u001b[32m\"unsafe_model.pt:unsafe_model/data.pkl\"\u001b[0m, \u001b[32m\"scanner\"\u001b[0m: \n",
      "\u001b[32m\"modelscan.scanners.PickleUnsafeOpScan\"\u001b[0m, \u001b[32m\"severity\"\u001b[0m: \u001b[32m\"CRITICAL\"\u001b[0m\u001b[1m}\u001b[0m\u001b[1m]\u001b[0m, \u001b[32m\"errors\"\u001b[0m: \u001b[1m[\u001b[0m\u001b[1m]\u001b[0m\u001b[1m}\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# This will save the scan results in file: pytorch-model-scan-results.json\n",
    "!modelscan --path  ./PyTorchModels/unsafe_model.pt -r json -o PyTorchModels/pytorch-model-scan-results.json"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.13 ('py310')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  },
  "vscode": {
   "interpreter": {
    "hash": "bd638e2064d9001d4ca93bc8e56e039dad230900dd235e8a6196f1614960903a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
